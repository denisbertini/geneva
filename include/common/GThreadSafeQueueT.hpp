/**
 * @file GThreadSafeQueueT.hpp
 */

/*
 * This file is part of the Geneva library collection.
 *
 * Note: this class was adapted from an example provided by Anthony
 * Williams along with his (highly recommended) book "Concurrency
 * in Action" / Manning . The code is covered by the Boost Software
 * License 1.0 . The original code and all remaining portions in the
 * code below are Copyright Anthony Williams.
 *
 * As allowed by the license, modifications were applied to the code.
 * These are also covered by the Boost Software License, Version 1.0, and are
 * Copyright (C) Gemfony scientific UG (haftungsbeschraenkt)
 *
 * NOTE THAT THE BOOST-LICENSE DOES NOT APPLY TO ANY OTHER FILES OF THE
 * GENEVA LIBRARY, UNLESS THIS IS EXPLICITLY STATED IN THE CORRESPONDING FILE!
 * See the AUTHORS file in the top-level directory for a list of authors.
 *
 * Contact: contact [at] gemfony (dot) eu
 *
 * Geneva was developed with kind support from Karlsruhe Institute of
 * Technology (KIT) and Steinbuch Centre for Computing (SCC). Further
 * information about KIT and SCC can be found at http://www.kit.edu/english
 * and http://scc.kit.edu .
 *
 * Geneva is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * Boost Software License for more details.
 *
 * For further information on Gemfony scientific and Geneva, visit
 * http://www.gemfony.eu .
 */

/*
 * The following license applies to the code in this file:
 *
 * ***************************************************************************
 *
 * Boost Software License - Version 1.0 - August 17th, 2003
 *
 * Permission is hereby granted, free of charge, to any person or organization
 * obtaining a copy of the software and accompanying documentation covered by
 * this license (the "Software") to use, reproduce, display, distribute,
 * execute, and transmit the Software, and to prepare derivative works of the
 * Software, and to permit third-parties to whom the Software is furnished to
 * do so, all subject to the following:
 *
 * The copyright notices in the Software and this entire statement, including
 * the above license grant, this restriction and the following disclaimer,
 * must be included in all copies of the Software, in whole or in part, and
 * all derivative works of the Software, unless such copies or derivative
 * works are solely in the form of machine-executable object code generated by
 * a source language processor.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
 * SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
 * FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 *
 * ***************************************************************************
 */

// Global checks, defines and includes needed for all of Geneva
#include "common/GGlobalDefines.hpp"

// Standard headers go here
#include <memory>
#include <mutex>
#include <atomic>
#include <type_traits>

// Boost headers go here

#ifndef GTHREADSAFEQUEUET_HPP_
#define GTHREADSAFEQUEUET_HPP_

// Geneva headers go here
#include "common/GCommonEnums.hpp"

namespace Gem {
namespace Common {

// TODO: Make this an optionally bounded queue --> done
// TODO: Make this queue fit for pushing std::shared_ptr and std::unique_ptr into it --> done
// TODO: Introduce timed waits

/******************************************************************************/
/**
 * A queue-like structure featuring thread-safe access and fine-grained locking.
 * Modelled after an implementation provided by Anthony Williams in his book
 * "C++ Concurrency in Action" (Manning).
 *
 * @tparam T The type of the data stored in this class
 * @tparam t_capacity The maximum number of data items to be stored in this class (0 means unlimited)
 */
template<
	typename T
	, std::size_t t_capacity = DEFAULTBUFFERSIZE
>
class GThreadSafeQueueT {
private:
	 /**
	  * A struct to be instantiated for each new data set stored in the queue
	  */
	 struct node
	 {
		  std::shared_ptr<T> data;
		  std::unique_ptr<node> next;
	 };

	 std::mutex m_head_mutex; ///< Protects access to the head node
	 std::mutex m_tail_mutex; ///< Protects access to the tail node

	 std::unique_ptr<node> m_head_ptr; ///< Points to the head of the linked list
	 node* m_tail_ptr; ///< Points to the tail of the linked list

	 std::condition_variable m_not_empty; ///< Allows to wait until new nodes have appeared
	 std::condition_variable m_not_full;  ///< Allows to wait until space becomes available in the data structure

	 std::atomic<std::size_t> m_n_data_sets = 0; ///< The number of data sets stored in this class

	 node* get_tail() {
		 std::unique_lock<std::mutex> tail_lock(m_tail_mutex);
		 return m_tail_ptr;
	 }

	 std::unique_ptr<node> pop_head() {
		 std::unique_ptr<node> const old_head=std::move(m_head_ptr);
		 m_head_ptr=std::move(old_head->next);

#ifdef DEBUG
		 assert(m_n_data_sets.load() >= 1);
#endif /* DEBUG */

		 m_n_data_sets--;

#ifdef GENEVA_COMMON_BOUNDED_BUFFER_USE_NOTIFY_ALL
		 m_not_full.notify_all();
#else
		 m_not_full.notify_one();
#endif

		 return old_head;
	 }

	 std::unique_lock<std::mutex> wait_for_data() {
		 std::unique_lock<std::mutex> head_lock(m_head_mutex);
		 m_not_empty.wait(head_lock,[&]{return m_head_ptr!=get_tail();});
		 return std::move(head_lock);
	 }

	 std::unique_ptr<node> wait_pop_head() {
		 std::unique_lock<std::mutex> head_lock(wait_for_data());
		 return pop_head();
	 }

	 std::unique_ptr<node> wait_pop_head(T& value) {
		 std::unique_lock<std::mutex> head_lock(wait_for_data());
		 value=std::move(*m_head_ptr->data);
		 return pop_head();
	 }

	 std::unique_ptr<node> try_pop_head() {
		 std::unique_lock<std::mutex> head_lock(m_head_mutex);
		 if(m_head_ptr.get()==get_tail()) {
			 return std::unique_ptr<node>();
		 }
		 return pop_head();
	 }

	 std::unique_ptr<node> try_pop_head(T& value) {
		 std::unique_lock<std::mutex> head_lock(m_head_mutex);
		 if(m_head_ptr.get()==get_tail()) {
			 return std::unique_ptr<node>();
		 }
		 value=std::move(*m_head_ptr->data);
		 return pop_head();
	 }

	 std::unique_lock<std::mutex> wait_for_space(
		 typename std::enable_if<(t_capacity>0)>::type* = 0
	 ) {
		 std::unique_lock<std::mutex> tail_lock(m_tail_mutex);
		 m_not_full.wait(
			 tail_lock
			 , [&] { return m_n_data_sets.load() < t_capacity; }
		 );
		 return std::move(tail_lock);
	 }

	 std::unique_lock<std::mutex> wait_for_space(
		 typename std::enable_if<(t_capacity==0)>::type* = 0
	 ) {
		 std::unique_lock<std::mutex> tail_lock(m_tail_mutex);
		 return std::move(tail_lock);
	 }

public:
	 GThreadSafeQueueT():
		 m_head_ptr(new node)
		 ,m_tail_ptr(m_head_ptr.get())
	 { /* nothing */ }

	 GThreadSafeQueueT(const GThreadSafeQueueT& other)=delete;
	 GThreadSafeQueueT& operator=(const GThreadSafeQueueT& other)=delete;

	 void push(
		 T new_value
		 , typename std::enable_if<std::is_move_constructible<T>::value || std::is_copy_constructible<T>::value>::type* = 0
	 ) {
		 std::shared_ptr<T> new_data(std::make_shared<T>(std::move(new_value)));
		 std::unique_ptr<node> p(new node);
		 {
			 std::unique_lock<std::mutex> tail_lock(wait_for_space());
			 m_tail_ptr->data=new_data;
			 node* const new_tail=p.get();
			 m_tail_ptr->next=std::move(p);
			 m_tail_ptr=new_tail;
			 m_n_data_sets++;
		 }
#ifdef GENEVA_COMMON_BOUNDED_BUFFER_USE_NOTIFY_ALL
		 m_not_empty.notify_all();
#else
		 m_not_empty.notify_one();
#endif
	 }

	 void push(std::shared_ptr<T> new_value_ptr) {
		 std::unique_ptr<node> p(new node);
		 {
			 std::unique_lock<std::mutex> tail_lock(wait_for_space());
			 m_tail_ptr->data=new_value_ptr;
			 node* const new_tail=p.get();
			 m_tail_ptr->next=std::move(p);
			 m_tail_ptr=new_tail;
			 m_n_data_sets++;
		 }
#ifdef GENEVA_COMMON_BOUNDED_BUFFER_USE_NOTIFY_ALL
		 m_not_empty.notify_all();
#else
		 m_not_empty.notify_one();
#endif
	 }

	 void push(std::unique_ptr<T>& new_value_ptr) {
		 std::unique_ptr<node> p(new node);
		 {
			 std::unique_lock<std::mutex> tail_lock(wait_for_space());
			 m_tail_ptr->data=std::shared_ptr<T>(new_value_ptr.release());
			 node* const new_tail=p.get();
			 m_tail_ptr->next=std::move(p);
			 m_tail_ptr=new_tail;
			 m_n_data_sets++;
		 }
#ifdef GENEVA_COMMON_BOUNDED_BUFFER_USE_NOTIFY_ALL
		 m_not_empty.notify_all();
#else
		 m_not_empty.notify_one();
#endif
	 }

	 std::shared_ptr<T> wait_and_pop() {
		 std::unique_ptr<node> const old_head=wait_pop_head();
		 return old_head->data;
	 }

	 // TODO: Was soll diese Funktion ? Warum das Assignment ?
	 void wait_and_pop(T& value) {
		 std::unique_ptr<node> const old_head=wait_pop_head(value);
	 }

	 std::shared_ptr<T> try_pop() {
		 std::unique_ptr<node> const old_head=try_pop_head();
		 return old_head?old_head->data:std::shared_ptr<T>();
	 }

	 bool try_pop(T& value) {
		 std::unique_ptr<node> const old_head=try_pop_head(value);
		 if(!old_head) return false;
		 value = *old_head;
		 return true;
	 }

	 bool empty() {
		 std::unique_lock<std::mutex> head_lock(m_head_mutex);
		 return (m_head_ptr==get_tail());
	 }
};

/******************************************************************************/

} /* namespace Common */
} /* namespace Gem */

#endif /* GTHREADSAFEQUEUET_HPP_ */
