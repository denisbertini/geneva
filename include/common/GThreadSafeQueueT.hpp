/**
 * @file GThreadSafeQueueT.hpp
 */

/*
 * This file is part of the Geneva library collection.
 *
 * Note: this class was adapted from an example provided by Anthony
 * Williams along with his (highly recommended) book "Concurrency
 * in Action" / Manning . The code is covered by the Boost Software
 * License 1.0 . The original code and all remaining portions in the
 * code below are Copyright Anthony Williams.
 *
 * As allowed by the license, modifications were applied to the code.
 * These are also covered by the Boost Software License, Version 1.0, and are
 * Copyright (C) Gemfony scientific UG (haftungsbeschraenkt)
 *
 * NOTE THAT THE BOOST-LICENSE DOES NOT APPLY TO ANY OTHER FILES OF THE
 * GENEVA LIBRARY, UNLESS THIS IS EXPLICITLY STATED IN THE CORRESPONDING FILE!
 * See the AUTHORS file in the top-level directory for a list of authors.
 *
 * Contact: contact [at] gemfony (dot) eu
 *
 * Geneva was developed with kind support from Karlsruhe Institute of
 * Technology (KIT) and Steinbuch Centre for Computing (SCC). Further
 * information about KIT and SCC can be found at http://www.kit.edu/english
 * and http://scc.kit.edu .
 *
 * Geneva is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * Boost Software License for more details.
 *
 * For further information on Gemfony scientific and Geneva, visit
 * http://www.gemfony.eu .
 */

/*
 * The following license applies to the code in this file:
 *
 * ***************************************************************************
 *
 * Boost Software License - Version 1.0 - August 17th, 2003
 *
 * Permission is hereby granted, free of charge, to any person or organization
 * obtaining a copy of the software and accompanying documentation covered by
 * this license (the "Software") to use, reproduce, display, distribute,
 * execute, and transmit the Software, and to prepare derivative works of the
 * Software, and to permit third-parties to whom the Software is furnished to
 * do so, all subject to the following:
 *
 * The copyright notices in the Software and this entire statement, including
 * the above license grant, this restriction and the following disclaimer,
 * must be included in all copies of the Software, in whole or in part, and
 * all derivative works of the Software, unless such copies or derivative
 * works are solely in the form of machine-executable object code generated by
 * a source language processor.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
 * SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
 * FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 *
 * ***************************************************************************
 */

// Global checks, defines and includes needed for all of Geneva
#include "common/GGlobalDefines.hpp"

// Standard headers go here
#include <memory>
#include <mutex>
#include <atomic>
#include <type_traits>

// Boost headers go here

#ifndef GTHREADSAFEQUEUET_HPP_
#define GTHREADSAFEQUEUET_HPP_

// Geneva headers go here
#include "common/GCommonEnums.hpp"

namespace Gem {
namespace Common {

// TODO: Make this an optionally bounded queue --> done
// TODO: Make this queue fit for pushing std::shared_ptr and std::unique_ptr into it
// TODO: Introduce timed waits

/******************************************************************************/

template<
	typename T
	, std::size_t t_capacity = DEFAULTBUFFERSIZE
>
class threadsafe_queue {
private:
	 struct node
	 {
		  std::shared_ptr<T> data;
		  std::unique_ptr<node> next;
	 };

	 std::mutex head_mutex;
	 std::unique_ptr<node> head;
	 std::mutex tail_mutex;
	 node* tail;
	 std::condition_variable m_not_empty; ///< Allows to wait until new nodes have appeared
	 std::condition_variable m_not_full; ///< Allows to wait until space becomes available in the data structure

	 std::atomic<std::size_t> n_data_sets = 0;

	 node* get_tail() {
		 std::unique_lock<std::mutex> tail_lock(tail_mutex);
		 return tail;
	 }

	 std::unique_ptr<node> pop_head() {
		 std::unique_ptr<node> const old_head=std::move(head);
		 head=std::move(old_head->next);
#ifdef DEBUG
		 assert(n_data_sets.load() >= 1);
#endif /* DEBUG */
		 n_data_sets--;
		 m_not_full.notify_one();
		 return old_head;
	 }

	 std::unique_lock<std::mutex> wait_for_data() {
		 std::unique_lock<std::mutex> head_lock(head_mutex);
		 m_not_empty.wait(head_lock,[&]{return head!=get_tail();});
		 return std::move(head_lock);
	 }

	 std::unique_ptr<node> wait_pop_head() {
		 std::unique_lock<std::mutex> head_lock(wait_for_data());
		 return pop_head();
	 }

	 std::unique_ptr<node> wait_pop_head(T& value) {
		 std::unique_lock<std::mutex> head_lock(wait_for_data());
		 value=std::move(*head->data);
		 return pop_head();
	 }

	 std::unique_ptr<node> try_pop_head() {
		 std::unique_lock<std::mutex> head_lock(head_mutex);
		 if(head.get()==get_tail()) {
			 return std::unique_ptr<node>();
		 }
		 return pop_head();
	 }

	 std::unique_ptr<node> try_pop_head(T& value) {
		 std::unique_lock<std::mutex> head_lock(head_mutex);
		 if(head.get()==get_tail()) {
			 return std::unique_ptr<node>();
		 }
		 value=std::move(*head->data);
		 return pop_head();
	 }

	 std::unique_lock<std::mutex> wait_for_space(
		 typename std::enable_if<(t_capacity>0)>::type* = 0
	 ) {
		 std::unique_lock<std::mutex> tail_lock(tail_mutex);
		 m_not_full.wait(
			 tail_lock
			 , [&] { return n_data_sets.load() < t_capacity; }
		 );
		 return std::move(tail_lock);
	 }

	 std::unique_lock<std::mutex> wait_for_space(
		 typename std::enable_if<(t_capacity==0)>::type* = 0
	 ) {
		 std::unique_lock<std::mutex> tail_lock(tail_mutex);
		 return std::move(tail_lock);
	 }

public:
	 threadsafe_queue():
		 head(new node)
		 ,tail(head.get())
	 { /* nothing */ }

	 threadsafe_queue(const threadsafe_queue& other)=delete;
	 threadsafe_queue& operator=(const threadsafe_queue& other)=delete;

	 void push(T new_value) {
		 std::shared_ptr<T> new_data(std::make_shared<T>(std::move(new_value)));
		 std::unique_ptr<node> p(new node);
		 {
			 std::unique_lock<std::mutex> tail_lock(wait_for_space());
			 tail->data=new_data;
			 node* const new_tail=p.get();
			 tail->next=std::move(p);
			 tail=new_tail;
			 n_data_sets++;
		 }
		 m_not_empty.notify_one();
	 }

	 void push(std::shared_ptr<T> new_value_ptr) {
		 std::unique_ptr<node> p(new node);
		 {
			 std::unique_lock<std::mutex> tail_lock(wait_for_space());
			 tail->data=new_value_ptr;
			 node* const new_tail=p.get();
			 tail->next=std::move(p);
			 tail=new_tail;
			 n_data_sets++;
		 }
		 m_not_empty.notify_one();
	 }

	 void push(std::unique_ptr<T>& new_value_ptr) {
		 std::unique_ptr<node> p(new node);
		 {
			 std::unique_lock<std::mutex> tail_lock(wait_for_space());
			 tail->data=std::shared_ptr<T>(new_value_ptr.release());
			 node* const new_tail=p.get();
			 tail->next=std::move(p);
			 tail=new_tail;
			 n_data_sets++;
		 }
		 m_not_empty.notify_one();
	 }

	 std::shared_ptr<T> wait_and_pop() {
		 std::unique_ptr<node> const old_head=wait_pop_head();
		 return old_head->data;
	 }

	 void wait_and_pop(T& value) {
		 std::unique_ptr<node> const old_head=wait_pop_head(value);
	 }

	 std::shared_ptr<T> try_pop() {
		 std::unique_ptr<node> const old_head=try_pop_head();
		 return old_head?old_head->data:std::shared_ptr<T>();
	 }

	 bool try_pop(T& value) {
		 std::unique_ptr<node> const old_head=try_pop_head(value);
		 if(!old_head) return false;
		 value = *old_head;
		 return true;
	 }

	 bool empty() {
		 std::unique_lock<std::mutex> head_lock(head_mutex);
		 return (head==get_tail());
	 }
};

/******************************************************************************/

} /* namespace Common */
} /* namespace Gem */

#endif /* GTHREADSAFEQUEUET_HPP_ */
