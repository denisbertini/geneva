- Add cross-over function to GStdVector interfaces
- Shifting in multi-populations
- Use one of the Boost logging library candidates. Requires that at least one 
  of them heads for a review (we do not want to include further candidate libraries. Geneva should work with a 
  vanilla Boost installation (>= 1.36)
- data_time usage in GBasePopulation::optimize() might lead to problems in multi-populations (-> thread-safety)
- Add a CMake macro "FindGeneva.cmake"
- Allow clients in network mode to pull over a series of individuals
- Transfer parents rather than children
- Allow clients to create a series of copies from the master individual by themself and return the best one
- Additional network implementations (MPI, PVM, ...)
- Implement *1.5 vs. /0.5 rule for sigma adaption. Can be based on the parentCounter_ variable
  of individuals.
- GSelectedChar should allow a selection of the characters to be mutated. Very similar:
  An integer class that allows mutation between several selected integers only.
- Clean up comments and run doxygen
- Implement a "trap" in GRandom and provide specializations for "allowed" types rather than 
  specializations for "forbidden" types
- Check how often the GRandomFactory queue is empty or full. Automatic adaption of number of threads ?
- Implement a chi-square test for the randomness of our generator, as a basic means of ensuring that 
  our random number generator does the right thing.
- When boundaries are at the maximum in GBoundedNumT<>, simply return the "in" value after the transformation
- Network transfer of the parent rather than the child to avoid transfer of multiple, identical child items
  Local duplication AND mutation
- Clients may ask to be sent m>n items, sending back only the n best items. Needs new command duplicate.
  Order DUPLICATE(M) -> MUTATE -> EVALUATE. Earlier orders imply the latter
- Network transfers initiated by clients in separate thread, in parallel to the calculation, thereby eliminating 
  part of the network overhead
- It should be possible to ask individuals to take charge of the external evaluation of other individuals as well, avoiding generation of local, random copies
- Add GSwarm, GSteepestDescent ?
- Catch signals in the network clients, so that we are sure that we complete network transfers before stopping
- Use the Boost.Filesystem library to access data on the disk - makes Geneva portable to Windows.
- GThreadGroup could be given a vector interface
- gLite submission script
- Observe, which parameters change a lot in successful mutations. Try to predominantly modify these parameters and keep the other parameters const. Could be done with a kind of line search ?
- Create a script or small program that emits the inidividual's .hpp and .cpp stubs, ready to be be completed by the user. Something along the lines of 
  "createStubs.sh myIndividualClassName
- Do checks for equality and similarity of base types through GObject::notEqual() and GObject::notSimilar(), that can 
  additionally emit information on the location of the deviation, if requested. Performance is not an issue for these functions
- The GNeuralNetworkIndividual needs to be renovated (e.g. a checkRelationshipWith() function needs to be added). Move to "UseCases".
- Also renovate GNoisyParabolaIndividual and GProjectionIndividual (still needed ?)
- Separate useful individuals (neural network, external evaluation, ...) from pure examples
- Create boost::shared_ptr<GObject> versions of load() and clone(), adapt in all places (e.g. GStdPtrVectorInterface.hpp)
- Test that seeding works with local random number creation
- Check whether we need to declare anything as volatile, particularly in connection with random number generation
- Remove the eval_ function from GParameterSet ... . Useless in parallel environments (?)
- Check in GStdPtrVectorInterface whether smart pointers actually point somewhere. Otherwise
  just copy an empty pointer (or throw ?? Different behavior in DEBUG mode ?)
- Check all load code whether it checks for empty smart pointers. Always check in DEBUG mode.
- Switch examples to the noisy parabola, due to its higher learning potential
- Renovation of client / consumer infrastructure (clean base classes, separation of protocol from network implementation).
  Possibly: Network code as function objects ?
- Test check-pointing of Geneva objects
- Check how many individuals are left out for large populations in networked mode, because of late arrival
- Profile the server part of networked execution. Is de-serialization always necessary ?
- Some error checks can be simplified if GBrokerPopulation tells its individuals that they are running on a server, where
  e.g. value calculation is not allowed.
- Allow to pass an arbitrary output stream to the info function
- Check that in multiple multi-threaded clients the seed is not identical due to local increment at the same rate
- Check for all variables in CMakeLists.txt whether they are already set. Hence e.g the CMake_Install_Prefix will gain a higher priority when set on the command line
- Generic GBaseClient. Can be achieved by making the object type to be processed a template argument
- Statistics in GBrokerPopulation about the number of drop-outs, parents and childs from current and older generations
- int_type GRandom::discreteRandom(const int_type& max) might yield bad results for large max values.
  Better multiply the maximum allowed value for int_type with a random double [0:1] and down-cast ?
- Make local vs. factory production of random numbers a template parameter for GRandom, so we
  can avoid the "switch" overhead. Or use purely virtual base class, with "factory" and "local" derivatives
- Can we use the Boost rnr-distributions with a factory or local generator in order to produce 
  different random distributions ? 
- Use http://www.boost.org/doc/libs/1_39_0/libs/random/nondet_random.html for the 
  generation of a non-deterministic start seed
- Add a test that shows whether local production continues with the same sequence after de-serialization
- Cloning, loading and copy construction of GRandom currently instantiates a new local generator. Modify so that there are
  really identical copies, but fix the Geneva code to re-initialize the local random seed, where needed. 
- Switch GRandom::initialSeed_ to boost::rand48's int32_t return format
- Add a remote console, allowing to retrieve information about the fitness history and other parameters, as well as
  providing an interface to setting certain crucial parameters. Can use a map<boost::int32_t, boost::function<std::string ()> > for
  the mapping between commands and local functions.
- Hide the core-Geneva headers in a single header for easier usage
- Create a "dlopen individual", capable of loading external libraries for the evaluation step (Boost has a plug-in framework in the making)
- Check boost::optional for return values and indicating valid return values
- get rid of the lazy evaluation ?
- Add an example covering the "traveling salesman" problem
- De-central sorting (by letting clients communicate)
- Script that scans which files contain which license types and creates a report
- Make individuals optionally output their information in ROOT-tree format (see http://root.cern.ch). Can
  be done with the info function framework ??
- Recycling of partially used random number blocks. Can be done by also storing the current01-pointer in the array and 
  re-injecting the array in the random-factory's queue. Also reduces the size of the GRandom objects. Recycling should be
  triggered upon destruction of the GRandom object, or when another production mode is chosen.
- Add checkForInequality/Dissimilarity function for boost::shared_ptr<complex_type> (useful e.g. for GSwarm)
- Consider some optimizations for the serialization process, e.g. see the section "Class Information" discussed
  e.g. here: http://www.boost.org/doc/libs/1_41_0/libs/serialization/doc/special.html .
- Check the issues involved in possible differences in size of std::size_t described in 
  http://www.boost.org/doc/libs/1_41_0/libs/serialization/doc/special.html 	-> Numerics
- Change general mutate calls (e.g. in the adaptors) to the more generic "adapt" -- a cosmetic change, but 
  appears important in the light of the fact that adaptions are not called mutations in optimization algorithms 
  other than evolutionary algorithms.
- Instead of "GBoundedInt32" etc. create classes like "template GBoundedInt<int bitSize = 32>" with a useful
  default value
- use Boost.enable_if to check allowed template instantiations
- Check whether we can make use of http://www.taygeta.com/random/gaussian.html to create gaussian random numbers more quickly 
  and whether we can indeed use both y1 and y2 values without fear of correlations ? Benchmark the traditional vs. the
  method proposed in this web page
- Check whether we can replace getAdaptorId with some typeid construct.
- Make local and factory production of random numbers a template, controlled through a define
- Add ability to lock vector wrappers, making it impossible to change the individual entries or size
- Add a "boost::atomic<T>" wrapper around data items accessed by more than one thread. E.g., access to uint64_t is apparently not atomic on x86_32
- Renovate GStartIndividual so that it uses a view of the supplied collections to gain access to its data
- Add continuation criterium: "At least x percent of all child individuals must have returned" (Ariel). Should be
  rated higher than the time constraint ("waitFactor") or could replace it.
- Add (de-)serialization tests for the new, independent GRandom lib
